## ğŸ“š æŠ€æœ¯æ–‡æ¡£

### æ•°æ®é‡‡é›†ç­–ç•¥

#### 1. Reddit é‡‡é›†å™¨

**æŠ€æœ¯æ–¹æ¡ˆ**: Selenium + Chrome Headless

**å®ç°ç»†èŠ‚**:
- ä½¿ç”¨ `webdriver-manager` è‡ªåŠ¨ç®¡ç† ChromeDriver
- é‡‡ç”¨ç”¨æˆ·é…ç½®æ–‡ä»¶æŒä¹…åŒ–ç™»å½•çŠ¶æ€
- æ™ºèƒ½æ»šåŠ¨æ£€æµ‹é¡µé¢åº•éƒ¨
- åçˆ¬è™«æªæ–½ï¼š
  - ç¦ç”¨è‡ªåŠ¨åŒ–æ§åˆ¶ç‰¹å¾
  - ä½¿ç”¨çœŸå® User-Agent
  - éšè— `navigator.webdriver` å±æ€§

**é‡‡é›†æµç¨‹**:
1. æœç´¢æŒ‡å®šå…³é”®è¯
2. æ»šåŠ¨åŠ è½½æ›´å¤šç»“æœï¼ˆæœ€å¤š 20 æ¬¡æ»šåŠ¨ï¼‰
3. æå–å¸–å­åˆ—è¡¨ï¼ˆæ ‡é¢˜ã€URLã€æŠ•ç¥¨æ•°ç­‰ï¼‰
4. è®¿é—®è¯¦æƒ…é¡µè·å–å®Œæ•´å†…å®¹
5. è¿‡æ»¤åƒåœ¾å†…å®¹

**å…³é”®ä»£ç ä½ç½®**: `backend/src/collectors/reddit.py`

**åçˆ¬è™«ç­–ç•¥**:
- æ— å¤´æ¨¡å¼è¿è¡Œ
- è‡ªå®šä¹‰ User-Agent
- CDP (Chrome DevTools Protocol) éšè—è‡ªåŠ¨åŒ–ç‰¹å¾
- éšæœºç­‰å¾…æ—¶é—´

---

#### 2. YouTube é‡‡é›†å™¨

**æŠ€æœ¯æ–¹æ¡ˆ**: YouTube Data API v3 + youtube-transcript-api

**å®ç°ç»†èŠ‚**:
- é€šè¿‡ YouTube Data API v3 æœç´¢è§†é¢‘
- ä½¿ç”¨ `youtube-transcript-api` è·å–å­—å¹•
- æ”¯æŒä»£ç†é…ç½®ï¼ˆWebshare ä½å®…ä»£ç† / HTTP ä»£ç†ï¼‰
- è¶…æ—¶é…ç½®é€‚é…ä¸­å›½ç½‘ç»œç¯å¢ƒ

**é‡‡é›†æµç¨‹**:
1. è°ƒç”¨ YouTube Data API æœç´¢è§†é¢‘
2. æå–è§†é¢‘å…ƒæ•°æ®ï¼ˆæ ‡é¢˜ã€æè¿°ã€ç»Ÿè®¡ä¿¡æ¯ï¼‰
3. è·å–è§†é¢‘å­—å¹•/è½¬å½•æ–‡æœ¬
4. ç»„åˆæ ‡é¢˜ + å­—å¹•ä½œä¸ºåˆ†æå†…å®¹

**ä»£ç†æ”¯æŒ**:
- Webshare ä½å®…ä»£ç†ï¼ˆæ¨èç”Ÿäº§ç¯å¢ƒï¼‰
- é€šç”¨ HTTP/HTTPS ä»£ç†
- ç¯å¢ƒå˜é‡é…ç½®ï¼š
  ```bash
  HTTP_PROXY=http://127.0.0.1:7890
  WEBSHARE_PROXY_USERNAME=username
  WEBSHARE_PROXY_PASSWORD=password
  ```

**å…³é”®ä»£ç ä½ç½®**: `backend/src/collectors/youtube.py`

---

#### 3. Twitter/X é‡‡é›†å™¨

**æŠ€æœ¯æ–¹æ¡ˆ**: Selenium çˆ¬è™«ï¼ˆæœªç™»å½•è®¿é—®ï¼‰

**å®ç°ç»†èŠ‚**:
- ç±»ä¼¼ Reddit çš„ Selenium æ–¹æ¡ˆ
- éœ€è¦å¤„ç† Twitter çš„åŠ¨æ€åŠ è½½
- åçˆ¬è™«è¦æ±‚æ›´é«˜

**æ³¨æ„äº‹é¡¹**:
- Twitter çˆ¬è™«å®¹æ˜“å¤±è´¥
- å¯èƒ½éœ€è¦ç™»å½•æ‰èƒ½è·å–å®Œæ•´æ•°æ®
- å»ºè®®é™ä½é‡‡é›†é¢‘ç‡é¿å…å°ç¦

**å…³é”®ä»£ç ä½ç½®**: `backend/src/collectors/twitter.py`

---

### AI Prompt è®¾è®¡

#### 1. æƒ…æ„Ÿåˆ†æ Prompt

**è®¾è®¡ç­–ç•¥**: Few-shot Learning + é“¾å¼æ€ç»´

**æ ¸å¿ƒç‰¹ç‚¹**:
- 8 ä¸ªç²¾å¿ƒè®¾è®¡çš„ç¤ºä¾‹ï¼ˆæ¶µç›–ç§¯æã€æ¶ˆæã€ä¸­æ€§ï¼‰
- åŒ…å«æ¨ç†è¿‡ç¨‹ï¼ˆreasoningï¼‰å¼•å¯¼æ¨¡å‹æ€è€ƒ
- æ˜ç¡®è¯„åˆ†æ ‡å‡†ï¼ˆ0-100 åˆ†åˆ¶ï¼‰

**ç¤ºä¾‹ Prompt**:

```
You are a sentiment analysis expert. Analyze the sentiment of social media posts on a 0-100 scale.

Text: This product is absolutely amazing! Best purchase I've ever made. Highly recommend to everyone!
Analysis: Score=95, Label=positive
Reasoning: Strong positive words (amazing, best, highly recommend) with exclamation marks indicate very positive sentiment

Text: Terrible experience. The product broke after one day and customer service was unhelpful.
Analysis: Score=15, Label=negative
Reasoning: Negative words (terrible, broke, unhelpful) with specific complaints indicate extremely negative sentiment

[... æ›´å¤šç¤ºä¾‹ ...]

Text: {user_input}
Analysis:
```

**è¯„åˆ†æ ‡å‡†**:
- 0-20: æåº¦è´Ÿé¢ï¼ˆä»‡æ¨ã€æ„¤æ€’ã€åŒæ¶ï¼‰
- 21-40: è´Ÿé¢ï¼ˆå¤±æœ›ã€æ²®ä¸§ï¼‰
- 41-60: ä¸­æ€§ï¼ˆå®¢è§‚äº‹å®ã€å¹³è¡¡è§‚ç‚¹ï¼‰
- 61-80: æ­£é¢ï¼ˆæ»¡æ„ã€è®¤å¯ï¼‰
- 81-100: æåº¦æ­£é¢ï¼ˆå–œçˆ±ã€å…´å¥‹ï¼‰

**å…³é”®ä»£ç ä½ç½®**: `backend/src/ai_analysis/prompts/sentiment_prompts.py`

---

#### 2. è§‚ç‚¹èšç±» Prompt

**è®¾è®¡ç­–ç•¥**: Few-shot + ç»“æ„åŒ–è¾“å‡º

**ç›®æ ‡**: å°†å¤§é‡è¯„è®ºå½’çº³ä¸º 3-5 ä¸ªä¸»è¦è§‚ç‚¹

**Prompt ç»“æ„**:
```
You are an expert at analyzing public opinion and identifying main discussion themes.

Given the following social media posts about "{keyword}", identify the top 3 main opinion clusters.

Requirements:
1. Each cluster should represent a distinct theme/topic
2. Assign a short label to each cluster
3. Provide a brief summary
4. Count how many posts mention this theme

Example:
Input: Posts about iPhone 16
Output:
1. "Battery Life" - Many users report shorter battery life compared to previous models (15 mentions)
2. "Camera Quality" - Praise for improved low-light performance and new features (12 mentions)
3. "Price Concerns" - Some users find the price increase unjustified (8 mentions)

Now analyze these posts:
{posts}

Output the top 3 opinion clusters in the same format:
```

**å…³é”®ä»£ç ä½ç½®**: `backend/src/ai_analysis/prompts/clustering_prompts.py`

---

#### 3. æ‘˜è¦ç”Ÿæˆ Prompt

**è®¾è®¡ç­–ç•¥**: Map-Reduce æ¨¡å¼å¤„ç†é•¿æ–‡æœ¬

**Map é˜¶æ®µ**:
```
Summarize the key points from these social media posts about "{keyword}" in 2-3 sentences.

Posts:
{chunk}

Summary:
```

**Reduce é˜¶æ®µ**:
```
Combine these summaries into a comprehensive 2-3 sentence overview:

{summaries}

Combined Summary:
```

**ä¼˜åŒ–ç­–ç•¥**:
- è¶…è¿‡ 3000 tokens è‡ªåŠ¨å¯ç”¨ Map-Reduce
- åˆ†æ‰¹å¤„ç†ï¼Œæ¯æ‰¹æœ€å¤š 30 æ¡å¸–å­
- æ™ºèƒ½é‡‡æ ·ä»£è¡¨æ€§å¸–å­

**å…³é”®ä»£ç ä½ç½®**: `backend/src/ai_analysis/prompts/summarization_prompts.py`

---

### Token ä¼˜åŒ–ç­–ç•¥

#### 1. Map-Reduce æ¨¡å¼

**è§¦å‘æ¡ä»¶**:
- æƒ…æ„Ÿåˆ†æï¼š> 4000 tokens
- èšç±»ï¼š> 4000 tokens
- æ‘˜è¦ï¼š> 3000 tokens

**å®ç°æ–¹å¼**:
1. **Map é˜¶æ®µ**: åˆ†æ‰¹å¤„ç†æ–‡æœ¬ï¼Œç”Ÿæˆä¸­é—´ç»“æœ
2. **Reduce é˜¶æ®µ**: åˆå¹¶ä¸­é—´ç»“æœï¼Œç”Ÿæˆæœ€ç»ˆè¾“å‡º

**ä¼˜åŠ¿**:
- èŠ‚çœ 17-35% Token æˆæœ¬
- é¿å…ä¸Šä¸‹æ–‡é•¿åº¦é™åˆ¶
- æé«˜å¤„ç†ç¨³å®šæ€§

**å…³é”®ä»£ç ä½ç½®**: `backend/src/ai_analysis/utils/map_reduce.py`

---

#### 2. æ–‡æœ¬é¢„å¤„ç†

**ç­–ç•¥**:
- æå–å…³é”®å¥ï¼ˆèŠ‚çœ 60-80% tokensï¼‰
- æˆªæ–­è¿‡é•¿æ–‡æœ¬
- ç§»é™¤ HTML æ ‡ç­¾å’Œç‰¹æ®Šå­—ç¬¦
- è¿‡æ»¤åƒåœ¾å†…å®¹ï¼ˆå¹¿å‘Šã€ä¹±ç ï¼‰

**ç¤ºä¾‹**:
```python
from src.ai_analysis.utils import TextPreprocessor

# æå–å…³é”®å¥
key_sentences = TextPreprocessor.extract_key_sentences(text, max_sentences=5)

# æ¸…ç†å’Œæˆªæ–­
cleaned = TextPreprocessor.clean_for_analysis(text, max_length=1000)
```

---

#### 3. æ‰¹é‡å¤„ç†

**æƒ…æ„Ÿåˆ†ææ‰¹å¤„ç†**:
- æ¯æ‰¹æœ€å¤š 10 æ¡å¸–å­
- å¹¶è¡Œè°ƒç”¨ API
- å‡å°‘ç½‘ç»œå¼€é”€

**æˆæœ¬å¯¹æ¯”**ï¼ˆ100 æ¡å¸–å­ï¼Œgpt-4o-miniï¼‰:

| ç‰ˆæœ¬ | Input Tokens | Output Tokens | æ€»è®¡ | æˆæœ¬ |
|------|-------------|---------------|------|------|
| æ—§ç‰ˆ | ~12,000 | ~2,800 | ~14,800 | ~$0.023 |
| æ–°ç‰ˆï¼ˆç›´æ¥ï¼‰ | ~10,000 | ~2,500 | ~12,500 | ~$0.019 |
| æ–°ç‰ˆï¼ˆMap-Reduceï¼‰ | ~8,000 | ~2,000 | ~10,000 | ~$0.015 |

**èŠ‚çœ**: 17-35%

---

### å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

#### 1. Reddit é‡‡é›†å¤±è´¥

**é—®é¢˜**: Selenium æ‰¾ä¸åˆ°å…ƒç´ æˆ–é¡µé¢åŠ è½½è¶…æ—¶

**è§£å†³æ–¹æ¡ˆ**:
- å¢åŠ ç­‰å¾…æ—¶é—´ï¼š`time.sleep(5)`
- æ£€æŸ¥é€‰æ‹©å™¨æ˜¯å¦æ›´æ–°ï¼ˆReddit ç»å¸¸æ›´æ–° DOMï¼‰
- ä½¿ç”¨æ›´å®½æ¾çš„å®šä½ç­–ç•¥
- æŸ¥çœ‹æ—¥å¿—ï¼š`backend/logs/trendpulse_*.log`

**è°ƒè¯•è„šæœ¬**:
```bash
cd backend
python scripts/diagnose_reddit.py
```

---

#### 2. YouTube å­—å¹•è·å–å¤±è´¥

**é—®é¢˜**: `TranscriptsDisabled` æˆ– `NoTranscriptFound` é”™è¯¯

**åŸå› **:
- è§†é¢‘æœªå¼€å¯å­—å¹•
- åœ°åŒºé™åˆ¶
- ç½‘ç»œé—®é¢˜ï¼ˆä¸­å›½åœ°åŒºéœ€è¦ä»£ç†ï¼‰

**è§£å†³æ–¹æ¡ˆ**:
1. **é…ç½®ä»£ç†**:
   ```bash
   HTTP_PROXY=http://127.0.0.1:7890
   ```

2. **ä½¿ç”¨ Webshare ä½å®…ä»£ç†**ï¼ˆæ¨èç”Ÿäº§ç¯å¢ƒï¼‰:
   ```bash
   WEBSHARE_PROXY_USERNAME=your_username
   WEBSHARE_PROXY_PASSWORD=your_password
   ```

3. **å¢åŠ è¶…æ—¶æ—¶é—´**:
   ```python
   # åœ¨ youtube.py ä¸­
   self.timeout = aiohttp.ClientTimeout(total=120)
   ```

---

#### 3. AI åˆ†ææˆæœ¬è¿‡é«˜

**é—®é¢˜**: Token æ¶ˆè€—è¶…å‡ºé¢„ç®—

**è§£å†³æ–¹æ¡ˆ**:
1. **ä½¿ç”¨æ›´ä¾¿å®œçš„æ¨¡å‹**:
   ```bash
   # ä½¿ç”¨é€šä¹‰åƒé—®ï¼ˆä¸­æ–‡æ›´ä¼˜ï¼Œä»·æ ¼æ›´ä½ï¼‰
   LLM_PROVIDER=tongyi
   TONGYI_MODEL=qwen-plus
   ```

2. **å¯ç”¨ Map-Reduce**:
   ```python
   pipeline = AnalysisPipelineV2(use_map_reduce=True)
   ```

3. **è·³è¿‡ä¸å¿…è¦çš„åˆ†æ**:
   ```python
   result = await pipeline.analyze_posts(posts, options={
       "skip_clustering": True  # è·³è¿‡èšç±»
   })
   ```

4. **é‡‡æ ·ä»£è¡¨æ€§å¸–å­**:
   ```python
   sampled_posts = posts[:30]  # åªåˆ†æå‰ 30 æ¡
   ```

---

#### 4. æ•°æ®åº“é”å®šé”™è¯¯

**é—®é¢˜**: `sqlite3.OperationalError: database is locked`

**åŸå› **: SQLite ä¸æ”¯æŒé«˜å¹¶å‘å†™æ“ä½œ

**è§£å†³æ–¹æ¡ˆ**:
1. **ä½¿ç”¨è¿æ¥æ± **:
   ```python
   # åœ¨ operations.py ä¸­é…ç½®
   engine = create_engine(
       DATABASE_URL,
       pool_size=5,
       max_overflow=10
   )
   ```

2. **ç”Ÿäº§ç¯å¢ƒè¿ç§»åˆ° PostgreSQL**:
   ```bash
   # ä¿®æ”¹ DATABASE_URL
   DATABASE_URL=postgresql+asyncpg://user:pass@localhost/trendpulse
   ```

---

#### 5. Twitter çˆ¬è™«è¢«å°ç¦

**é—®é¢˜**: è´¦å·è¢«å°æˆ– IP è¢«é™åˆ¶

**è§£å†³æ–¹æ¡ˆ**:
1. **é™ä½é‡‡é›†é¢‘ç‡**:
   ```python
   time.sleep(random.uniform(5, 10))  # éšæœºç­‰å¾… 5-10 ç§’
   ```

2. **ä½¿ç”¨ä»£ç†æ± **:
   ```bash
   HTTP_PROXY=http://proxy-server:port
   ```

3. **æ¨¡æ‹Ÿäººç±»è¡Œä¸º**:
   - éšæœºæ»šåŠ¨é€Ÿåº¦
   - éšæœºé¼ æ ‡ç§»åŠ¨
   - ä¸é‡‡é›†æ—¶å…³é—­æµè§ˆå™¨

---
