# AI åˆ†ææ¶æ„å‡çº§è¯´æ˜ (LangChain ç‰ˆæœ¬)

## æ¦‚è§ˆ

æˆ‘ä»¬å·²å°† AI åˆ†ææ¨¡å—é‡æ„ä¸ºä½¿ç”¨ **LangChain** æ¡†æ¶ï¼Œå¸¦æ¥ä»¥ä¸‹æ”¹è¿›ï¼š

### ä¸»è¦ç‰¹æ€§

1. **LangChain é›†æˆ** - ä½¿ç”¨ LangChain è¿›è¡Œ LLM è°ƒç”¨å’Œé“¾å¼å¤„ç†
2. **Map-Reduce æ¨¡å¼** - è‡ªåŠ¨å¤„ç†é•¿æ–‡æœ¬ï¼Œä¼˜åŒ– Token ä½¿ç”¨
3. **Token è¿½è¸ª** - è¯¦ç»†è®°å½•æ¯æ¬¡ API è°ƒç”¨çš„ Token ä½¿ç”¨å’Œæˆæœ¬
4. **æ¨¡å—åŒ– Prompt** - ç‹¬ç«‹çš„ Prompt æ¨¡å—ï¼Œæ”¯æŒ Few-shot å­¦ä¹ 
5. **å¢å¼ºæ—¥å¿—** - å®Œæ•´çš„æ“ä½œæ—¥å¿—å’Œæ€§èƒ½æŒ‡æ ‡

## æ¶æ„è®¾è®¡

### æ–°å¢æ¨¡å—ç»“æ„

```
backend/src/ai_analysis/
â”œâ”€â”€ prompts/                      # Prompt æ¨¡æ¿æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ sentiment_prompts.py      # æƒ…æ„Ÿåˆ†æ Prompt (Few-shot)
â”‚   â”œâ”€â”€ clustering_prompts.py     # èšç±» Prompt (Few-shot)
â”‚   â””â”€â”€ summarization_prompts.py  # æ‘˜è¦ Prompt (Few-shot)
â”‚
â”œâ”€â”€ utils/                        # å·¥å…·æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ logger.py                 # æ—¥å¿—å’Œ Token è¿½è¸ª
â”‚   â”œâ”€â”€ token_counter.py          # Token è®¡æ•°å’Œæ–‡æœ¬å¤„ç†
â”‚   â””â”€â”€ map_reduce.py             # Map-Reduce å¤„ç†å™¨
â”‚
â”œâ”€â”€ langchain_client.py           # LangChain LLM å®¢æˆ·ç«¯
â”œâ”€â”€ sentiment_v2.py               # æƒ…æ„Ÿåˆ†æ v2
â”œâ”€â”€ clustering_v2.py              # è§‚ç‚¹èšç±» v2
â”œâ”€â”€ summarizer_v2.py              # æ‘˜è¦ç”Ÿæˆ v2
â””â”€â”€ pipeline_v2.py                # åˆ†æç®¡é“ v2
```

### ä¿ç•™æ—§æ¨¡å—

æ—§ç‰ˆæœ¬æ¨¡å—ä¿ç•™ä»¥ä¿æŒå‘åå…¼å®¹ï¼š
- `client.py` - åŸå§‹ LLM å®¢æˆ·ç«¯
- `sentiment.py` - åŸå§‹æƒ…æ„Ÿåˆ†æ
- `clustering.py` - åŸå§‹èšç±»
- `summarizer.py` - åŸå§‹æ‘˜è¦
- `pipeline.py` - åŸå§‹ç®¡é“

## æ ¸å¿ƒç»„ä»¶

### 1. Prompt æ¨¡å— (`prompts/`)

ç‹¬ç«‹çš„ Prompt ç®¡ç†ï¼Œæ”¯æŒ Few-shot å­¦ä¹ ã€‚

```python
from src.ai_analysis.prompts import (
    create_sentiment_prompt_template,
    get_sentiment_system_prompt,
    SENTIMENT_EXAMPLES
)

# åˆ›å»ºå¸¦ Few-shot ç¤ºä¾‹çš„æ¨¡æ¿
prompt = create_sentiment_prompt_template()

# Few-shot ç¤ºä¾‹åŒ…å« 8 ä¸ªæ ‡æ³¨å¥½çš„æƒ…æ„Ÿåˆ†æç¤ºä¾‹
SENTIMENT_EXAMPLES = [
    {
        "text": "This product is absolutely amazing!",
        "score": 95,
        "label": "positive",
        "reasoning": "Strong positive words with exclamation"
    },
    # ... æ›´å¤šç¤ºä¾‹
]
```

### 2. æ—¥å¿—å’Œ Token è¿½è¸ª (`utils/logger.py`)

è‡ªåŠ¨è®°å½•æ‰€æœ‰ API è°ƒç”¨çš„è¯¦ç»†ä¿¡æ¯ã€‚

```python
from src.ai_analysis.utils import get_analysis_logger

logger = get_analysis_logger()

# è‡ªåŠ¨è¿½è¸ªæ¯æ¬¡ API è°ƒç”¨
logger.log_api_call(
    operation="sentiment_analysis",
    model="gpt-4o-mini",
    input_tokens=1500,
    output_tokens=300,
    duration=2.5
)

# æŸ¥çœ‹æ±‡æ€»
logger.log_token_summary()
# è¾“å‡º:
# ============================================================
# TOKEN USAGE SUMMARY
# ============================================================
# Total API Calls: 15
# Total Input Tokens: 12,500
# Total Output Tokens: 2,800
# Total Tokens: 15,300
# Estimated Cost: $0.0234
# ============================================================
```

### 3. Token è®¡æ•°å™¨ (`utils/token_counter.py`)

ç²¾ç¡®çš„ Token ä¼°ç®—å’Œæ–‡æœ¬å¤„ç†ã€‚

```python
from src.ai_analysis.utils import TokenCounter, TextPreprocessor

# è®¡æ•° Token
token_count = TokenCounter.count_tokens(text, model="gpt-4o-mini")

# æŒ‰ Token æˆªæ–­
truncated = TokenCounter.truncate_to_tokens(text, max_tokens=1000)

# æŒ‰ Token åˆ†å‰²
chunks = TokenCounter.split_text_by_tokens(
    text,
    max_tokens_per_chunk=2000,
    overlap=200
)

# é¢„å¤„ç†æ–‡æœ¬
cleaned = TextPreprocessor.clean_for_analysis(text, max_length=1000)

# æå–å…³é”®å¥
key_sentences = TextPreprocessor.extract_key_sentences(text, max_sentences=5)
```

### 4. Map-Reduce å¤„ç†å™¨ (`utils/map_reduce.py`)

è‡ªåŠ¨å¤„ç†é•¿æ–‡æœ¬ï¼Œä¼˜åŒ– Token ä½¿ç”¨ã€‚

```python
from src.ai_analysis.utils import MapReduceProcessor

processor = MapReduceProcessor(
    max_tokens_per_chunk=2000,
    overlap=200,
    batch_size=5
)

# å¤„ç†å•ä¸ªé•¿æ–‡æœ¬
async def map_func(chunk):
    return await analyze(chunk)

async def reduce_func(results):
    return combine(results)

result = await processor.process(
    text,
    map_func,
    reduce_func,
    operation_name="summarization"
)

# å¤„ç†å¤šä¸ªå¸–å­
result = await processor.process_posts(
    posts,
    map_batch,
    reduce_results,
    operation_name="clustering"
)
```

### 5. LangChain å®¢æˆ·ç«¯ (`langchain_client.py`)

å¢å¼ºçš„ LLM å®¢æˆ·ç«¯ï¼Œæ”¯æŒ Token è¿½è¸ªå’Œè‡ªåŠ¨é‡è¯•ã€‚

```python
from src.ai_analysis import LangChainLLMClient

client = LangChainLLMClient(
    provider="openai",  # or "tongyi"
    temperature=0.7,
    max_tokens=2000
)

# ç®€å•è°ƒç”¨
response = await client.invoke(
    prompt="Analyze this text",
    system_prompt="You are a sentiment analyzer"
)

# JSON å“åº”
result = await client.generate_json(
    prompt="Return JSON",
    system_prompt="Return valid JSON"
)

# åˆ›å»ºé“¾å¼è°ƒç”¨
chain = client.create_chain(system_prompt="...")
result = await client.run_chain(chain, {"input": "..."})

# æŸ¥çœ‹ç»Ÿè®¡
stats = client.get_token_summary()
```

## ä½¿ç”¨æ–¹å¼

### åŸºç¡€ç”¨æ³•

```python
from src.ai_analysis.pipeline_v2 import AnalysisPipelineV2

# åˆ›å»ºç®¡é“
pipeline = AnalysisPipelineV2(
    provider="openai",  # or "tongyi"
    use_map_reduce=True  # è‡ªåŠ¨ä½¿ç”¨ Map-Reduce å¤„ç†å¤§æ•°æ®
)

# åˆ†æå¸–å­
result = await pipeline.analyze_posts(posts)

# ç»“æœåŒ…å«:
# - sentiment_results: æƒ…æ„Ÿåˆ†æåˆ—è¡¨
# - overall_sentiment: æ•´ä½“æƒ…æ„Ÿ (0-100)
# - clusters: è§‚ç‚¹èšç±»
# - summary: è®¨è®ºæ‘˜è¦
# - token_usage: Token ä½¿ç”¨ç»Ÿè®¡
```

### é«˜çº§é€‰é¡¹

```python
result = await pipeline.analyze_posts(posts, options={
    "use_map_reduce": True,       # å¼ºåˆ¶ä½¿ç”¨ Map-Reduce
    "skip_clustering": False,      # è·³è¿‡èšç±»
    "skip_summary": False,         # è·³è¿‡æ‘˜è¦
    "top_n_clusters": 5            # è¿”å› Top 5 èšç±»
})
```

### ä»…æƒ…æ„Ÿåˆ†æï¼ˆå¿«é€Ÿæ¨¡å¼ï¼‰

```python
result = await pipeline.analyze_sentiment_only(posts)
# åªè¿”å›æƒ…æ„Ÿåˆ†æç»“æœï¼Œæ›´å¿«æ›´ä¾¿å®œ
```

## Token ä¼˜åŒ–ç­–ç•¥

### 1. è‡ªåŠ¨ Map-Reduce

å½“æ•°æ®é‡è¶…è¿‡é˜ˆå€¼æ—¶è‡ªåŠ¨å¯ç”¨ï¼š
- æƒ…æ„Ÿåˆ†æï¼š> 4000 tokens
- èšç±»ï¼š> 4000 tokens
- æ‘˜è¦ï¼š> 3000 tokens

### 2. æ–‡æœ¬é¢„å¤„ç†

```python
# è‡ªåŠ¨æˆªæ–­
TextPreprocessor.clean_for_analysis(text, max_length=1000)

# æå–å…³é”®å¥ï¼ˆèŠ‚çœ 60-80% tokensï¼‰
TextPreprocessor.extract_key_sentences(text, max_sentences=5)
```

### 3. æ‰¹é‡å¤„ç†

```python
# è‡ªåŠ¨åˆ†æ‰¹å¤„ç†ï¼Œæ¯æ‰¹æœ€å¤š 10 æ¡
await sentiment_analyzer.analyze_batch(texts)
```

### 4. æ™ºèƒ½é‡‡æ ·

```python
# è‡ªåŠ¨é‡‡æ ·ä»£è¡¨æ€§å¸–å­
# èšç±»ï¼šæœ€å¤š 50 æ¡
# æ‘˜è¦ï¼šæœ€å¤š 30 æ¡
```

## æˆæœ¬å¯¹æ¯”

### 100 æ¡å¸–å­åˆ†æï¼ˆOpenAI gpt-4o-miniï¼‰

| ç‰ˆæœ¬ | Input Tokens | Output Tokens | æ€»è®¡ | æˆæœ¬ |
|------|-------------|---------------|------|------|
| æ—§ç‰ˆ | ~12,000 | ~2,800 | ~14,800 | ~$0.023 |
| æ–°ç‰ˆ (ç›´æ¥) | ~10,000 | ~2,500 | ~12,500 | ~$0.019 |
| æ–°ç‰ˆ (Map-Reduce) | ~8,000 | ~2,000 | ~10,000 | ~$0.015 |

**èŠ‚çœ**: ~17-35% æˆæœ¬

## æ—¥å¿—ç¤ºä¾‹

```
2025-01-15 10:30:15 - ai_analysis - INFO - ğŸ”§ Using OpenAI LLM provider
2025-01-15 10:30:15 - ai_analysis - INFO - Initialized LangChain client with provider: openai, model: gpt-4o-mini
2025-01-15 10:30:15 - ai_analysis - INFO - Initialized AnalysisPipelineV2 with provider: openai
2025-01-15 10:30:15 - ai_analysis - INFO - ============================================================
2025-01-15 10:30:15 - ai_analysis - INFO - Starting AI analysis pipeline
2025-01-15 10:30:15 - ai_analysis - INFO - Posts: 50
2025-01-15 10:30:15 - ai_analysis - INFO - Map-Reduce: False
2025-01-15 10:30:15 - ai_analysis - INFO - ============================================================
2025-01-15 10:30:15 - ai_analysis - INFO - ğŸ“Š Step 1/3: Analyzing sentiment...
2025-01-15 10:30:16 - ai_analysis - INFO - [sentiment_analysis_batch] Progress: 1/5 (20.0%)
2025-01-15 10:30:18 - ai_analysis - INFO - API Call [sentiment_analysis_batch] | Model: gpt-4o-mini | Input: 1,200 tokens | Output: 450 tokens | Duration: 1.85s | Cost: $0.0023
...
2025-01-15 10:30:45 - ai_analysis - INFO - âœ“ Overall sentiment: 68.5/100
2025-01-15 10:30:45 - ai_analysis - INFO - ğŸ¯ Step 2/3: Clustering opinions...
2025-01-15 10:30:52 - ai_analysis - INFO - âœ“ Found 3 main opinion clusters
2025-01-15 10:30:52 - ai_analysis - INFO - ğŸ“ Step 3/3: Generating summary...
2025-01-15 10:30:58 - ai_analysis - INFO - âœ“ Summary generated (523 characters)
2025-01-15 10:30:58 - ai_analysis - INFO - ============================================================
2025-01-15 10:30:58 - ai_analysis - INFO - âœ… AI analysis pipeline completed!
2025-01-15 10:30:58 - ai_analysis - INFO - ============================================================
2025-01-15 10:30:58 - ai_analysis - INFO - ============================================================
2025-01-15 10:30:58 - ai_analysis - INFO - TOKEN USAGE SUMMARY
2025-01-15 10:30:58 - ai_analysis - INFO - ============================================================
2025-01-15 10:30:58 - ai_analysis - INFO - Total API Calls: 7
2025-01-15 10:30:58 - ai_analysis - INFO - Total Input Tokens: 8,542
2025-01-15 10:30:58 - ai_analysis - INFO - Total Output Tokens: 1,856
2025-01-15 10:30:58 - ai_analysis - INFO - Total Tokens: 10,398
2025-01-15 10:30:58 - ai_analysis - INFO - Estimated Cost: $0.0158
2025-01-15 10:30:58 - ai_analysis - INFO - ============================================================
```

## è¿ç§»æŒ‡å—

### ä»æ—§ç‰ˆè¿ç§»åˆ°æ–°ç‰ˆ

```python
# æ—§ç‰ˆ
from src.ai_analysis.pipeline import AnalysisPipeline

pipeline = AnalysisPipeline()
result = await pipeline.analyze_posts(posts)


# æ–°ç‰ˆ
from src.ai_analysis.pipeline_v2 import AnalysisPipelineV2

pipeline = AnalysisPipelineV2(provider="openai")
result = await pipeline.analyze_posts(posts)

# æ–°ç‰ˆå¢åŠ äº† token_usage å­—æ®µ
print(result["token_usage"])
# {'total': 10398, 'input': 8542, 'output': 1856, 'cost': 0.0158, 'api_calls': 7}
```

### å…¼å®¹æ€§

æ–°ç‰ˆä¿æŒä¸æ—§ç‰ˆç›¸åŒçš„ç»“æœæ ¼å¼ï¼š
- `sentiment_results`: ç›¸åŒæ ¼å¼
- `overall_sentiment`: ç›¸åŒæ ¼å¼
- `clusters`: ç›¸åŒæ ¼å¼
- `summary`: ç›¸åŒæ ¼å¼

æ–°å¢å­—æ®µï¼š
- `token_usage`: Token ä½¿ç”¨ç»Ÿè®¡

## é…ç½®

### ç¯å¢ƒå˜é‡

```bash
# LLM æä¾›å•†é€‰æ‹©
LLM_PROVIDER=openai  # or tongyi

# OpenAI é…ç½®
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-4o-mini
OPENAI_BASE_URL=https://api.openai.com/v1

# é€šä¹‰åƒé—®é…ç½®
TONGYI_API_KEY=sk-...
TONGYI_MODEL=qwen-plus
TONGYI_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
```

## æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. å°æ•°æ®é›†ï¼ˆ< 50 æ¡ï¼‰
```python
pipeline = AnalysisPipelineV2(use_map_reduce=False)
# ç›´æ¥å¤„ç†ï¼Œæ›´å¿«
```

### 2. å¤§æ•°æ®é›†ï¼ˆ> 100 æ¡ï¼‰
```python
pipeline = AnalysisPipelineV2(use_map_reduce=True)
# ä½¿ç”¨ Map-Reduceï¼Œæ›´çœ Token
```

### 3. ä»…éœ€æƒ…æ„Ÿåˆ†æ
```python
result = await pipeline.analyze_sentiment_only(posts)
# è·³è¿‡èšç±»å’Œæ‘˜è¦ï¼ŒèŠ‚çœ ~60% æˆæœ¬
```

### 4. è‡ªå®šä¹‰é‡‡æ ·
```python
# é¢„å…ˆé‡‡æ ·ä»£è¡¨æ€§å¸–å­
sampled_posts = posts[:30]
result = await pipeline.analyze_posts(sampled_posts)
```

## æ•…éšœæ’æŸ¥

### é—®é¢˜ï¼šToken è®¡æ•°ä¸å‡†ç¡®

```python
# ä½¿ç”¨ tiktoken ç²¾ç¡®è®¡æ•°
import tiktoken
encoding = tiktoken.encoding_for_model("gpt-4o-mini")
tokens = encoding.encode(text)
print(f"Exact tokens: {len(tokens)}")
```

### é—®é¢˜ï¼šMap-Reduce å¤„ç†å¤±è´¥

```python
# å›é€€åˆ°ç›´æ¥å¤„ç†
result = await pipeline.analyze_posts(posts, options={
    "use_map_reduce": False
})
```

### é—®é¢˜ï¼šæˆæœ¬è¿‡é«˜

```python
# 1. ä½¿ç”¨æ›´ä¾¿å®œçš„æ¨¡å‹
Config.OPENAI_MODEL = "gpt-4o-mini"  # è€Œé gpt-4o

# 2. ä½¿ç”¨é€šä¹‰åƒé—®
pipeline = AnalysisPipelineV2(provider="tongyi")

# 3. è·³è¿‡ä¸éœ€è¦çš„åˆ†æ
result = await pipeline.analyze_posts(posts, options={
    "skip_clustering": True
})
```

## ä¸‹ä¸€æ­¥ä¼˜åŒ–

1. **ç¼“å­˜æœºåˆ¶** - ç¼“å­˜ç›¸ä¼¼å†…å®¹çš„åˆ†æç»“æœ
2. **æµå¼è¾“å‡º** - å®æ—¶è¿”å›åˆ†æç»“æœ
3. **å¹¶è¡Œå¤„ç†** - åŒæ—¶æ‰§è¡Œå¤šä¸ªåˆ†æä»»åŠ¡
4. **å¢é‡åˆ†æ** - ä»…åˆ†ææ–°å¢å†…å®¹
5. **Prompt ä¼˜åŒ–** - æŒç»­æ”¹è¿› Prompt è´¨é‡

## ç›¸å…³æ–‡æ¡£

- [AI åˆ†ææµç¨‹æ–‡æ¡£](./AI_ANALYSIS.md) - è¯¦ç»†çš„æµç¨‹è¯´æ˜
- [Prompt è®¾è®¡æŒ‡å—](./PROMPT_ENGINEERING.md) - Prompt å·¥ç¨‹æœ€ä½³å®è·µ
