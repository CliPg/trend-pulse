# TrendPulse Database Design

## Overview

TrendPulse uses SQLAlchemy ORM with SQLite as the default database. The database follows a relational model designed to store social media posts, keywords, and AI analysis results.

**Technology Stack:**
- ORM: SQLAlchemy 2.x with AsyncIO support
- Database: SQLite (with `aiosqlite` for async operations)
- Connection String: `sqlite+aiosqlite:///./trendpulse.db`

---

## Entity Relationship Diagram

```
+------------------+       +-------------------+
|   Keyword        |<----->|      Post         |
+------------------+       +-------------------+
| id (PK)          |       | id (PK)           |
| keyword          | 1    N | platform          |
| language         |       | post_id           |
| overall_sentiment|       | author            |
| summary          |       | content           |
| last_analyzed    |       | url               |
| created_at       |       | upvotes           |
+------------------+       | likes             |
         ^                | shares            |
         |                | comments_count    |
         |                | sentiment_score   |
         |                | sentiment_label   |
         |                | created_at        |
         |                | collected_at      |
         |                | keyword_id (FK)   |
         |                +-------------------+
         |                         ^
         |                         |
         |                +-------------------+
         |                | OpinionCluster    |
         |                +-------------------+
         |                | id (PK)           |
         |                | keyword_id (FK)   |
         |                | cluster_label     |
         |                | cluster_summary   |
         |                | representative_   |
         |                |   post_id (FK)    |
         |                | mention_count     |
         |                | created_at        |
         |                +-------------------+
         |
         |
+------------------+
|  AnalysisJob     |
+------------------+
| id (PK)          |
| keyword_id (FK)  |
| status           |
| platforms_scraped|
| posts_collected  |
| token_used       |
| error_message    |
| started_at       |
| completed_at     |
+------------------+
```

---

## Table Schema

### 1. Keywords Table

**Purpose:** Stores search keywords and their aggregated analysis results.

| Column | Type | Constraints | Description |
|--------|------|-------------|-------------|
| `id` | Integer | PRIMARY KEY, AUTO_INCREMENT | Unique identifier |
| `keyword` | String(255) | UNIQUE, NOT NULL | Search keyword/query |
| `language` | String(10) | DEFAULT='en' | Language code (en/zh) |
| `overall_sentiment` | Float | NULLABLE | Overall sentiment score (0-100) |
| `summary` | Text | NULLABLE | AI-generated summary |
| `last_analyzed` | DateTime | NULLABLE | Last analysis timestamp |
| `created_at` | DateTime | DEFAULT=NOW() | Record creation time |

**Relationships:**
- One-to-Many with `Post` (cascade delete)
- One-to-Many with `OpinionCluster`
- One-to-Many with `AnalysisJob`

**Notes:**
- `keyword` field is unique to prevent duplicate analysis
- `overall_sentiment` is calculated from average of all related posts' sentiment scores
- `summary` is generated by LLM from all collected posts

---

### 2. Posts Table

**Purpose:** Stores individual social media posts from all platforms.

| Column | Type | Constraints | Description |
|--------|------|-------------|-------------|
| `id` | Integer | PRIMARY KEY, AUTO_INCREMENT | Unique identifier |
| `platform` | String(50) | NOT NULL | Platform: 'reddit', 'youtube', 'twitter' |
| `post_id` | String(255) | NOT NULL | Platform-specific post ID |
| `author` | String(255) | NULLABLE | Username/author name |
| `content` | Text | NOT NULL | Post content/caption |
| `url` | String(2048) | NULLABLE | Original post URL |
| `created_at` | DateTime | DEFAULT=NOW() | Original post creation time |
| `collected_at` | DateTime | DEFAULT=NOW() | When we scraped this post |
| `upvotes` | Integer | DEFAULT=0 | Reddit upvotes |
| `likes` | Integer | DEFAULT=0 | YouTube likes |
| `shares` | Integer | DEFAULT=0 | Twitter shares/retweets |
| `comments_count` | Integer | DEFAULT=0 | Number of comments |
| `sentiment_score` | Float | NULLABLE | AI-calculated sentiment (0-100) |
| `sentiment_label` | String(50) | NULLABLE | 'positive', 'negative', 'neutral' |
| `keyword_id` | Integer | FOREIGN KEY | Reference to Keyword.id |

**Relationships:**
- Many-to-One with `Keyword`
- One-to-One with `OpinionCluster` (as representative post)

**Indexes:**
- Primary key on `id`
- Composite unique index recommended: `(platform, post_id)` to prevent duplicates

**Platform-Specific Fields:**
- **Reddit**: Uses `upvotes` and `comments_count`
- **YouTube**: Uses `likes` and `comments_count`
- **Twitter/X**: Uses `shares` (retweets) and `comments_count`

**Notes:**
- Content is stored as plain text (HTML/Markdown cleaned)
- `post_id` combined with `platform` should be unique across platforms
- Sentiment fields are NULL until AI analysis is completed

---

### 3. Opinion Clusters Table

**Purpose:** Stores grouped opinions/themes extracted from post analysis.

| Column | Type | Constraints | Description |
|--------|------|-------------|-------------|
| `id` | Integer | PRIMARY KEY, AUTO_INCREMENT | Unique identifier |
| `keyword_id` | Integer | FOREIGN KEY | Reference to Keyword.id |
| `cluster_label` | String(255) | NOT NULL | Short label for this opinion |
| `cluster_summary` | Text | NOT NULL | Detailed explanation |
| `representative_post_id` | Integer | FOREIGN KEY (nullable) | Example post for this cluster |
| `mention_count` | Integer | DEFAULT=0 | How many posts mention this |
| `created_at` | DateTime | DEFAULT=NOW() | When cluster was created |

**Relationships:**
- Many-to-One with `Keyword`
- Many-to-One with `Post` (representative post)

**Use Case:**
- AI analyzes all posts and groups similar opinions
- Example: For keyword "iPhone 16", clusters might be:
  - "Battery Life Concerns" (mention_count: 45)
  - "Camera Improvements" (mention_count: 32)
  - "Price Complaints" (mention_count: 28)

---

### 4. Analysis Jobs Table

**Purpose:** Tracks analysis execution for monitoring and debugging.

| Column | Type | Constraints | Description |
|--------|------|-------------|-------------|
| `id` | Integer | PRIMARY KEY, AUTO_INCREMENT | Unique identifier |
| `keyword_id` | Integer | FOREIGN KEY | Reference to Keyword.id |
| `status` | String(50) | DEFAULT='pending' | 'pending', 'processing', 'completed', 'failed' |
| `platforms_scraped` | String(255) | NULLABLE | Comma-separated: "reddit,youtube" |
| `posts_collected` | Integer | DEFAULT=0 | Total posts collected |
| `token_used` | Integer | DEFAULT=0 | LLM tokens consumed |
| `error_message` | Text | NULLABLE | Error details if failed |
| `started_at` | DateTime | DEFAULT=NOW() | Job start time |
| `completed_at` | DateTime | NULLABLE | Job end time |

**Relationships:**
- Many-to-One with `Keyword`

**Use Cases:**
- Debug failed scrapes
- Monitor API token usage
- Track performance metrics
- Implement rate limiting

---

## Database Operations

### Core Database Manager Class

Location: `backend/src/database/operations.py`

**Key Methods:**

```python
class DatabaseManager:
    async def init_db()                    # Create all tables
    async def create_keyword()             # Create new keyword
    async def get_or_create_keyword()      # Get existing or create new
    async def save_posts()                 # Bulk insert posts
    async def get_posts_by_keyword()       # Retrieve posts
    async def update_sentiment()           # Update post sentiment
    async def save_opinion_clusters()      # Save opinion clusters
    async def update_keyword_analysis()    # Update keyword summary
    async def get_all_keywords()           # List all keywords
    async def get_keyword_by_id()          # Get single keyword
    async def get_opinion_clusters()       # Get clusters for keyword
    async def close()                      # Close connection
```

---

## Usage Examples

### Example 1: Basic Workflow

```python
from src.database.operations import DatabaseManager

# Initialize
db = DatabaseManager("sqlite+aiosqlite:///./trendpulse.db")
await db.init_db()

# Create or get keyword
keyword = await db.get_or_create_keyword("iPhone 16", language="en")

# Save scraped posts
posts_data = [
    {
        "platform": "reddit",
        "post_id": "abc123",
        "author": "user123",
        "content": "Great camera but battery life is disappointing",
        "url": "https://reddit.com/r/Apple/comments/abc123",
        "upvotes": 150,
        "comments_count": 45
    },
    # ... more posts
]
saved_posts = await db.save_posts(posts_data, keyword.id)

# Update sentiment after AI analysis
await db.update_sentiment(
    post_id=saved_posts[0].id,
    score=65.5,
    label="neutral"
)

# Save opinion clusters
clusters = [
    {
        "label": "Camera Quality",
        "summary": "Users praise the improved camera system",
        "mention_count": 32
    },
    {
        "label": "Battery Life",
        "summary": "Many users report shorter battery life",
        "mention_count": 45
    }
]
await db.save_opinion_clusters(clusters, keyword.id)

# Update keyword with final results
await db.update_keyword_analysis(
    keyword_id=keyword.id,
    overall_sentiment=58.2,
    summary="Mixed reviews with camera improvements praised but battery life criticized"
)
```

### Example 2: Querying Analysis Results

```python
# Get keyword with all data
keyword = await db.get_keyword_by_id(1)
posts = await db.get_posts_by_keyword(1)
clusters = await db.get_opinion_clusters(1)

print(f"Keyword: {keyword.keyword}")
print(f"Overall Sentiment: {keyword.overall_sentiment}/100")
print(f"Posts Collected: {len(posts)}")

for cluster in clusters:
    print(f"- {cluster.cluster_label}: {cluster.mention_count} mentions")
```

---

## Performance Considerations

### 1. Indexing Strategy

Current indexes:
- Primary keys on all tables
- Unique index on `keyword.keyword`

**Recommended additional indexes:**
```sql
-- Speed up sentiment filtering
CREATE INDEX idx_post_sentiment ON posts(sentiment_score);

-- Speed up platform-specific queries
CREATE INDEX idx_post_platform ON posts(platform);

-- Speed up job status queries
CREATE INDEX idx_job_status ON analysis_jobs(status);

-- Composite index for duplicate prevention
CREATE UNIQUE INDEX idx_post_unique ON posts(platform, post_id);
```

### 2. Query Optimization

**Batch Operations:**
- Use `save_posts()` for bulk inserts instead of individual inserts
- Commit transactions in batches for large datasets

**N+1 Query Prevention:**
```python
# BAD: N+1 queries
for post in posts:
    keyword = await db.get_keyword_by_id(post.keyword_id)

# GOOD: Eager loading with SQLAlchemy relationship
keyword = await db.get_keyword_by_id(keyword_id)
posts = await db.get_posts_by_keyword(keyword_id)
```

### 3. Async Benefits

- All database operations are async using `aiosqlite`
- Allows concurrent scraping without blocking
- Suitable for I/O-bound operations

### 4. Data Cleanup

**Recommended cleanup strategy:**
```python
# Delete old analysis jobs (keep last 100)
DELETE FROM analysis_jobs
WHERE id NOT IN (
    SELECT id FROM analysis_jobs
    ORDER BY started_at DESC
    LIMIT 100
);

# Delete keywords without posts (cleanup failed jobs)
DELETE FROM keywords
WHERE id NOT IN (SELECT DISTINCT keyword_id FROM posts);
```

---

## Migration Strategy

### Current Limitations

- No automatic migration system (Alembic not implemented)
- Schema changes require manual database recreation

### Adding New Fields

```python
# 1. Update model in models.py
class Post(Base):
    # ... existing fields
    new_field = Column(String(255))  # Add new field

# 2. Recreate database (DESTRUCTIVE)
rm trendpulse.db
await db.init_db()
```

### Production Migration Path

For production use, consider adding:
1. **Alembic** for database migrations
2. **Backup strategy** before schema changes
3. **Migration scripts** for data preservation

---

## Security Considerations

### 1. SQL Injection Prevention

- SQLAlchemy ORM automatically parameterizes queries
- Never use raw SQL with user input
- All inputs are properly escaped

### 2. Data Validation

- Pydantic models validate API inputs
- Database constraints enforce data integrity
- Content length limits prevent abuse

### 3. Sensitive Data

- No API keys stored in database
- User handles/IDs are public social media data
- Consider anonymizing if storing PII

---

## Future Enhancements

### Planned Features

1. **Caching Layer**
   - Redis for frequently accessed keywords
   - Cache TTL for analysis results

2. **Full-Text Search**
   - FTS5 on post content
   - Enable content-based filtering

3. **Time-Series Data**
   - Track sentiment trends over time
   - Historical sentiment comparison

4. **User Analytics**
   - Track most searched keywords
   - Monitor platform popularity

5. **PostgreSQL Migration**
   - Better for production scaling
   - Advanced features (JSONB, arrays)
   - Better concurrent write performance

---

## Troubleshooting

### Common Issues

**Issue: Database locked error**
```
sqlite3.OperationalError: database is locked
```
Solution: SQLite doesn't handle concurrent writes well. Use connection pooling or migrate to PostgreSQL.

**Issue: Foreign key constraint fails**
```
IntegrityError: FOREIGN KEY constraint failed
```
Solution: Ensure parent record exists before creating child records.

**Issue: Memory usage with large datasets**
Solution: Use pagination or process in batches:
```python
# Process 100 posts at a time
for i in range(0, len(posts), 100):
    batch = posts[i:i+100]
    await db.save_posts(batch, keyword_id)
```

---

## References

- **Code**: `backend/src/database/models.py`
- **Operations**: `backend/src/database/operations.py`
- **API**: `backend/src/api/main.py`
- **SQLAlchemy Docs**: https://docs.sqlalchemy.org/en/20/
- **aiosqlite**: https://aiosqlite.omnilib.dev/
