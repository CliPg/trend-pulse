"""
Reddit æ»šåŠ¨è¯Šæ–­å·¥å…·

ç”¨äºè¯Šæ–­ä¸ºä»€ä¹ˆåªèƒ½çˆ¬å–å°‘é‡å¸–å­
"""
import time
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
from urllib.parse import quote


def diagnose_reddit_scrolling():
    """è¯Šæ–­ Reddit æ»šåŠ¨åŠ è½½"""

    keyword = "artificial intelligence"
    search_url = f"https://www.reddit.com/search/?q={quote(keyword)}&type=posts"

    print("=" * 60)
    print("Reddit æ»šåŠ¨è¯Šæ–­å·¥å…·")
    print("=" * 60)
    print(f"\næœç´¢ URL: {search_url}")
    print("\næ­£åœ¨å¯åŠ¨æµè§ˆå™¨...\n")

    # é…ç½® Chrome
    chrome_options = Options()
    chrome_options.add_argument("--user-data-dir=chrome_profile")
    chrome_options.add_argument("--disable-blink-features=AutomationControlled")
    chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
    chrome_options.add_argument(f"--user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")

    # å¯åŠ¨æµè§ˆå™¨
    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=chrome_options)
    driver.set_window_size(1920, 1080)

    try:
        print("æ­£åœ¨è®¿é—® Reddit æœç´¢é¡µé¢...")
        driver.get(search_url)

        print("\nâ³ ç­‰å¾…é¡µé¢åŠ è½½ï¼ˆ5ç§’ï¼‰...")
        time.sleep(5)

        print("\n" + "=" * 60)
        print("å¼€å§‹æµ‹è¯•æ»šåŠ¨åŠ è½½")
        print("=" * 60)

        # æµ‹è¯•å¤šæ¬¡æ»šåŠ¨
        for scroll_iteration in range(5):
            print(f"\n--- æ»šåŠ¨è¿­ä»£ {scroll_iteration + 1} ---")

            # æŸ¥æ‰¾å¸–å­å…ƒç´ 
            posts1 = driver.find_elements("css selector", '[data-testid="search-post-unit"]')
            posts2 = driver.find_elements("css selector", '[data-testid="search-post-with-content-preview"]')

            print(f"  [data-testid=\"search-post-unit\"] æ‰¾åˆ°: {len(posts1)} ä¸ª")
            print(f"  [data-testid=\"search-post-with-content-preview\"] æ‰¾åˆ°: {len(posts2)} ä¸ª")
            print(f"  æ€»è®¡: {len(posts1) + len(posts2)} ä¸ªå¸–å­")

            # æ˜¾ç¤ºå‰3ä¸ªå¸–å­çš„æ ‡é¢˜
            all_posts = posts1 + posts2
            if all_posts:
                print(f"\n  å‰3ä¸ªå¸–å­æ ‡é¢˜:")
                for i, post in enumerate(all_posts[:3], 1):
                    try:
                        title = post.find_element("css selector", '[data-testid="post-title-text"]')
                        print(f"    {i}. {title.text[:60]}...")
                    except:
                        print(f"    {i}. (æ— æ³•è·å–æ ‡é¢˜)")

            # æ»šåŠ¨åˆ°åº•éƒ¨
            print(f"\n  æ»šåŠ¨åˆ°é¡µé¢åº•éƒ¨...")
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")

            # ç­‰å¾…åŠ è½½
            print(f"  ç­‰å¾…3ç§’...")
            time.sleep(3)

            # æ£€æŸ¥é¡µé¢é«˜åº¦
            scroll_height = driver.execute_script("return document.body.scrollHeight")
            current_scroll = driver.execute_script("return window.pageYOffset")
            print(f"  é¡µé¢é«˜åº¦: {scroll_height}px")
            print(f"  å½“å‰æ»šåŠ¨ä½ç½®: {current_scroll}px")

        print("\n" + "=" * 60)
        print("è¯Šæ–­å®Œæˆï¼")
        print("=" * 60)
        print("\nğŸ’¡ åˆ†æ:")
        print("   å¦‚æœå¸–å­æ•°é‡æ²¡æœ‰å¢åŠ ï¼Œå¯èƒ½æ˜¯å› ä¸º:")
        print("   1. Reddit éœ€è¦æ›´é•¿çš„ç­‰å¾…æ—¶é—´")
        print("   2. éœ€è¦ç™»å½•æ‰èƒ½æŸ¥çœ‹æ›´å¤šå†…å®¹")
        print("   3. é¡µé¢ä½¿ç”¨äº†è™šæ‹Ÿæ»šåŠ¨ï¼Œå…ƒç´ ä¼šè¢«å¤ç”¨")
        print("   4. é€‰æ‹©å™¨ä¸æ­£ç¡®")

        input("\næŒ‰ Enter é”®å…³é—­æµè§ˆå™¨...")

    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

    finally:
        driver.quit()


if __name__ == "__main__":
    diagnose_reddit_scrolling()
